// local-server.cjs
// ê¹ƒí—ˆë¸Œ Pages + ngrok ì „ìš© ë¡œì»¬ ì„œë²„ (CommonJS ë²„ì „)

const express = require("express");
const cors = require("cors");
require("dotenv").config();
const OpenAI = require("openai");

const client = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
});

const app = express();

// JSON ë°”ë”” íŒŒì‹±
app.use(express.json());

// CORS (ê°œë°œìš©: ì „ë¶€ í—ˆìš©, ë‚˜ì¤‘ì—” íŠ¹ì • ë„ë©”ì¸ë§Œ í—ˆìš©í•´ë„ ë¨)
app.use(
  cors({
    origin: "*", // ë‚˜ì¤‘ì— "https://USERNAME.github.io" ë¡œ ë°”ê¿”ë„ ë¨
  })
);

// /chat ì—”ë“œí¬ì¸íŠ¸
app.post("/chat", async (req, res) => {
  try {
    const body = req.body || {};
    const userMessage = body.message || "";

    if (!userMessage) {
      return res.status(400).json({ message: "message ê°€ ë¹„ì–´ ìžˆìŠµë‹ˆë‹¤." });
    }

    const completion = await client.chat.completions.create({
      model: "gpt-4.1-mini",
      messages: [
        { role: "system", content: "ë„ˆëŠ” ì¹œì ˆí•œ AR ì•ˆë‚´ ì±—ë´‡ì´ì•¼." },
        { role: "user", content: userMessage },
      ],
      max_tokens: 256,
      temperature: 0.7,
    });

    const reply = completion.choices[0].message.content;
    return res.json({ message: reply });
  } catch (err) {
    console.error("[server-error]", err);
    return res
      .status(500)
      .json({ message: "[server-error] " + (err.message || "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜") });
  }
});

const PORT = process.env.PORT || 8000;
app.listen(PORT, () => {
  console.log(`ðŸš€ Local chat server running at http://localhost:${PORT}/chat`);
});
